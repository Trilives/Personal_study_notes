 **“Aubo机械臂 + 灵心灵巧手” 按摩机器人项目第一阶段（第1-3个月）详细周计划**。
---

### 第一阶段：基础架构搭建与硬件联调（第 1 - 4 周）

**核心目标：** 完成 ROS2 开发环境搭建，打通 Aubo 机械臂与灵心灵巧手的底层通信，实现“脑（PC）- 手（机械臂）- 指（灵巧手）”的指令传输。

#### 第 1 周：ROS2 环境构建与仿真预热

* **周一/周二：** 安装 Ubuntu 22.04 LTS 及 ROS2 Humble Hawksbill（目前最稳定版本）。配置开发环境（VSCode, Terminator, Git）。
* **周三：** 学习 ROS2 通信模型。重点编写简单的 Publisher/Subscriber 节点（C++ 或 Python），理解 DDS 通信延迟。
* **周四：** 获取 Aubo 官方 ROS2 驱动包（通常为 `aubo_robot` 或 `aubo_ros2_driver`），在 Rviz 中加载 URDF 模型，熟悉关节定义。
* **周五：** 硬件准备。购买 USB-CAN 转换器（建议创芯科技或同类稳定芯片）或 USB-RS485 转换器，为灵巧手调试做准备。
* **本周产出：** 能够在 Rviz 中看到 Aubo 机械臂模型，并能通过滑块（Joint State Publisher）控制模型运动。

#### 第 2 周：Aubo 机械臂实机控制

* **周一：** 机械臂物理连接。配置 PC 与 Aubo 控制柜的静态 IP（通常在同一网段，如 `192.168.1.x`），使用 `ping` 测试连通性。
* **周二：** 编译并运行 Aubo ROS2 驱动。解决依赖报错（如 `ros2_control` 相关包）。
* **周三：** 话题控制测试。通过 `ros2 topic pub` 发送简单的关节角度指令，观察机械臂是否响应。**注意：手放在急停按钮上。**
* **周四：** 编写 Python 脚本调用 Aubo 的 SDK 或 ROS Service，实现“解锁”、“使能”、“回零”操作。
* **周五：** 基础安全测试。测试碰撞停止阈值，配置软件限位，防止机械臂撞击桌子或自身。
* **本周产出：** 通过 ROS2 命令行或脚本，成功控制 Aubo 机械臂完成一次“点头”动作。

#### 第 3 周：灵心灵巧手驱动开发（难点）

* **周一：** 协议研读。**详细阅读灵心灵巧手的通信协议手册**。确认波特率、帧头、帧尾、校验位（CRC/Sum）以及控制寄存器地址（力控/位控模式）。
* **周二：** 串口调试。不连接 ROS，直接使用串口调试助手（Windows/Linux）通过 CAN/RS485 发送十六进制指令，测试灵巧手张开/闭合。
* **周三：** 编写 ROS2 硬件接口节点（Node）。使用 Python 的 `pyserial` 或 C++ 的 `socketcan`，将串口指令封装为 ROS2 的 Service（如 `/hand_control`）。
* **周四：** 状态反馈解析。解析灵巧手返回的报文（电流、位置），发布到 `/hand_state` 话题。
* **周五：** 联合调试。将灵巧手安装在 Aubo 法兰末端（可能需要定制 3D 打印连接件），处理线缆走线（防止缠绕）。
* **本周产出：** 一个自定义的 ROS2 Node，可以通过 Service 调用让灵巧手执行“抓捏”动作，并能读取其实时电流值（用于判断按摩力度）。

#### 第 4 周：TF 坐标系树与模型整合

* **周一：** URDF 模型拼接。编写 `.xacro` 文件，将 Aubo 的末端法兰（`tool0`）与灵心灵巧手的基座（`base_link`）通过 `fixed joint` 连接。
* **周二：** TF 树验证。启动 `robot_state_publisher`，在 Rviz 中检查 TF 树是否完整（Base -> Arm -> Flange -> Hand -> FingerTip）。
* **周三：** 标定修正。根据实际 3D 打印连接件的厚度，修正 URDF 中的 `origin xyz` 参数。
* **周四/周五：** 阶段性复盘与系统备份。整理代码库，编写 Readme，备份系统镜像。
* **本周产出：** Rviz 中显示带有灵巧手的完整机器人模型，且 TF 坐标变换无报错。

---

### 第二阶段：运动规划与按摩示教（第 5 - 8 周）

**核心目标：** 引入 MoveIt2 运动规划引擎，实现机械臂在笛卡尔空间的平滑运动，并完成第一套“按摩动作”的录制与复现。

#### 第 5 周：MoveIt2 配置与仿真

* **周一：** 运行 MoveIt Setup Assistant。加载拼接好的 Xacro 模型。
* **周二：** 配置 SRDF。定义规划组（Planning Group）：
* `arm`: Aubo 的 6 个关节。
* `hand`: 灵巧手（如果有独立关节控制）。
* 定义 `Home` 和 `Massage_Ready` 等预设姿态。


* **周三：** 碰撞矩阵（ACM）配置。禁用相邻连杆的碰撞检测，避免自碰撞误报。
* **周四：** 生成配置包（`aubo_hand_moveit_config`）。
* **周五：** 仿真规划。在 Rviz 中拖动末端执行器，使用 OMPL 规划器（如 RRTConnect）进行路径规划演示。
* **本周产出：** 能够拖动 Rviz 中的虚拟机械臂末端，并规划出一条避障路径。

#### 第 6 周：真机运动规划对接

* **周一：** Controller 配置。配置 `ros2_control`，将 MoveIt2 的 `FollowJointTrajectory` Action 连接到 Aubo 的驱动接口。
* **周二：** 真机同步。启动 MoveIt2，确保 Rviz 中的虚拟机器人与真实 Aubo 姿态实时同步。
* **周三：** 速度/加速度限制。**按摩需要柔顺**，在配置文件中将最大速度和加速度限制在 10%-20%，防止动作过猛。
* **周四：** 笛卡尔空间规划。编写 Python 脚本，使用 MoveIt PyBinding 控制末端沿直线（按摩轨迹）移动，而不是关节插值。
* **周五：** 调试抖动问题。观察机械臂运动是否平滑，如有抖动，调整 PID 参数或轨迹插值密度。
* **本周产出：** 代码控制 Aubo 机械臂末端走出标准的“正方形”或“圆形”轨迹。

#### 第 7 周：示教模式开发（拖动/记录）

* **周一：** 开启 Aubo 的重力补偿/拖动示教模式（通常厂家自带功能）。
* **周二：** 编写路点记录节点（Waypoint Recorder）。订阅 `/joint_states`，按下键盘按键时记录当前关节角。
* **周三：** 轨迹复现节点。读取记录的 CSV/YAML 文件，调用 MoveIt API 进行复现。
* **周四：** 结合灵巧手。在记录的路点中增加灵巧手动作指令（如：点 A [手张开] -> 点 B [手闭合/抓捏]）。
* **周五：** 模拟人体背部测试。在桌面上放置假人或枕头，手动拖动机械臂模拟按摩背部的轨迹并记录。
* **本周产出：** 成功录制并复现一套包含 5-10 个关键点的“背部推拿”动作。

#### 第 8 周：轨迹优化与安全

* **周一：** 轨迹平滑。使用样条插值（Spline Interpolation）处理录制的路点，消除复现时的停顿感。
* **周二：** 奇异点（Singularity）规避。分析按摩轨迹是否经过奇异区域，调整机械臂基座高度或位置。
* **周三/周四：** 异常处理机制。编写看门狗程序，当通信丢失或误差过大时自动触发 Halt（停止）。
* **周五：** 月度演示。展示从静止 -> 移动至按摩位 -> 执行录制轨迹 -> 灵巧手配合动作 -> 归位。

---

### 第三阶段：视觉感知与闭环控制（第 9 - 12 周）

**核心目标：** 加入深度相机，完成手眼标定，使机器人能看见“背部”并自动对齐按摩点，不再依赖盲目的固定轨迹。

#### 第 9 周：视觉硬件接入

* **周一：** 硬件安装。将深度相机（如 RealSense D435i 或 Orbbec Femto）固定在机械臂末端（眼在手上）或固定支架（眼在手外）。**推荐眼在手上（Eye-in-Hand）**，适合按摩这种近距离操作。
* **周二：** 驱动安装。安装 `realsense-ros` 或对应相机 ROS2 包。
* **周三：** 数据查看。在 Rviz 中查看 PointCloud2 点云数据和 RGB 图像。
* **周四：** 图像处理基础。使用 OpenCV 订阅图像话题，实现简单的 Canny 边缘检测或颜色分割。
* **周五：** 深度数据读取。读取特定像素点的深度值（距离）。
* **本周产出：** Rviz 中能实时看到相机拍摄的点云，且能随机械臂运动而移动。

#### 第 10 周：手眼标定（关键步骤）

* **周一：** 准备标定板。打印棋盘格（Checkerboard）或 AprilTag 标定纸，固定在平坦桌面上。
* **周二：** 安装标定软件。推荐使用 `easy_handeye` (ROS2版) 或 OpenCV 自带标定例程。
* **周三：** 数据采集。控制机械臂在不同角度拍摄标定板（通常需要 15-20 个姿态）。
* **周四：** 解算变换矩阵。计算 Camera 到 End-Effector 的变换矩阵 。
* **周五：** 验证标定。在 Rviz 中加载标定结果，观察点云是否与真实的机械臂模型位置对齐。
* **本周产出：** 获得高精度的手眼变换矩阵，并固化到 Launch 文件中。

#### 第 11 周：按摩区域识别

* **周一：** 场景定义。假设按摩区域为一个特定颜色的标记或大致平坦的人体背部区域。
* **周二：** 姿态估计。使用 PCA（主成分分析）或平面拟合算法（RANSAC），从点云中计算出背部的法向量（Normal Vector）。**按摩必须垂直于表面**。
* **周三：** 坐标变换。将视觉识别到的“按摩点”坐标（相机系）转换到“基座系”（Robot Base Link）。
* **周四：** 编写视觉伺服（Visual Servoing）雏形。让机械臂末端移动到距离目标点上方 10cm 处。
* **周五：** 综合测试。移动标定物，机器人能自动调整目标位置。
* **本周产出：** 无论物体放在哪（在工作范围内），机械臂都能移动到物体正上方并垂直于物体表面。

#### 第 12 周：第一阶段总集成与Demo

* **周一：** 状态机设计。设计简单的流程：待机 -> 视觉扫描 -> 规划路径 -> 接近 -> 执行按摩（配合灵巧手） -> 结束离开。
* **周二：** 代码集成。将前三个月的 ROS Node 整合到一个 Launch 文件中。
* **周三：** 力控模拟（伪力控）。利用灵巧手的电流反馈或 Aubo 的电流反馈，设定一个简单的阈值：如果接触阻力过大，机械臂轻微回退（模拟柔顺）。
* **周四：** 系统联调与Debug。
* **周五：** **里程碑演示**。在假人背部贴上标签，机器人自动识别，规划路径，机械臂下压，灵巧手进行捏合动作。

---

### 下一步建议

由于您使用的是 **Aubo + 灵心灵巧手**，第 3 周的驱动开发是最大的不确定因素。